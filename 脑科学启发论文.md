本章节主要关注脑科学等领域的研究对于人工神经网络的启发

Neuronal Avalanches in Neocortical Circuits
- https://www.jneurosci.org/content/23/35/11167
本文是首个提出大脑可能工作在 临界点 的论文。启发了神经网络可能就是一个大型的集群现象。

相关的论文：
[Signatures of criticality in a maximum entropy model of the C. elegans brain during free behaviour](https://www.researchgate.net/publication/319450365_Signatures_of_criticality_in_a_maximum_entropy_model_of_the_C_elegans_brain_during_free_behaviour)
[Whole-Brain Neuronal Activity Displays Crackling Noise Dynamics](https://www.sciencedirect.com/science/article/pii/S089662731830953X)
[Spontaneous cortical activity in awake monkeys composed of neuronal avalanches](https://www.pnas.org/doi/full/10.1073/pnas.0904089106?doi=10.1073/pnas.0904089106)

在认知心理学中有一个经典的概念：物体恒存性 (Object Permanence)。https://zh.wikipedia.org/zh-cn/%E7%89%A9%E9%AB%94%E6%81%86%E5%AD%98
其定义是：个体理解一个物体即使在感官（视觉、听觉等）无法察觉的情况下，它依然继续存在的认知能力。比如，我们看到一个人在前面走，我们知道前面有人。如果这个人突然左拐到了巷子里，我们会知道，他并没有消失，而是藏在左边的路口中。

这种记忆机制非常地有用，如果用算法来表达这个过程，那么对应的记忆变量，不应该是一个单独的值，而应该是一个序列，它能存储过去的观察，并将当前和过去的观察做一个平均，实现预测与更新。
具体的来说，这种记忆机制的应用有以下几个方法：

预测编码 (Predictive Coding)：
World Models and Predictive Coding for Cognitive and Developmental Robotics:
Frontiers and Challenges
- https://arxiv.org/pdf/2301.05832
有研究表明，基于预测编码策略的机器人模型可以自发地学习并展现出类似婴儿的物体恒存性行为。这些模型通过最小化预测误差，学会在物体被遮挡时预测其可能的位置。

状态空间模型与卡尔曼滤波器 (State-Space Models & Kalman Filter)
卡尔曼滤波器是一个递归算法，它通过一个两步过程来估计一个动态系统的状态（例如物体的位置和速度）：
- 预测 (Predict)：根据上一时刻的状态和物体的运动模型，预测当前时刻的状态。这代表了“过去的观察”。
- 更新/校正 (Update/Correct)：利用当前时刻的观察（测量值），来修正预测值，得到一个更精确的估计。这代表了“当前的观察”和“平均”的过程。

循环神经网络 (Recurrent Neural Networks, RNNs)
RNN网络中存在“隐藏状态 (hidden state)”，这个状态就像一个记忆单元，它会编码并传递过去时间步的信息。在处理序列中的每一个元素时，网络都会结合当前输入和前一时刻的隐藏状态，来更新当前的隐藏状态，并作出输出。

Explaining object permanence with a deep recurrent neural network model of human cortical visual cognition
- https://cordis.europa.eu/project/id/841578/reporting
- https://arxiv.org/abs/2401.06005
该研究使用深度循环神经网络来模拟人类的视觉认知，并成功解释了物体恒存性。
- 
