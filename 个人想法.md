## 个人想法

​	以下主要基于过去的专业以及阅读到的论文作出的一些看法。

​	个人觉得，机器人数据的获取是当前具身智能领域面临的主要挑战之一。首先，这类数据并非互联网现有的数据，而需要在实际机器人上重新采样获取，这会耗费大量人力和时间。数据获取是一个问题，Mobile Aloha 提供了一种简便的采样平台，此外，也有一些研究尝试在仿真环境中获取模拟数据。其次，不同形态的机器人本体各异，且现实世界中的任务类型极为多样，这导致不同机器人之间和不同场景下采样的数据难以通用。因此，研究者们通常倾向于使用相同类型的机器人本体和任务场景，例如机械臂在家庭场景做家务或人形机器人行走，因为这类机器人已有大量的相关数据可供使用。如果希望尝试新形态的机器人，则需要自行收集或生成大量该形态机器人在实际工作中的数据，这进一步增加了科研投入时间和成本。这也是当今为什么说, 要产学研结合，要找落地场景, 因为有价值的项目一定有人愿意来做, 用的人多了，就自然而然产生大量数据, 进一步推动该领域的算法, 从而形成正反馈，这也是当的新范式。

​	目前喜欢走用机器人数据这条路的原因，是曾经做计算机视觉的人又开始研究机器人了。ImagNet和GPT的成功让这些研究人员认为，只要数据足够，就可以学习到策略。

​	但作为从自动化毕业的我来说，我还是对此持有中立态度。一方面传统的基于建模和优化的方法确实很难应对本体愈发复杂的机器狗和人形机器人之类的硬件载体；另一方面，现在的机器人任务也愈发的多样化，不像曾经那样有单一稳定的工况，人们期望机器人要处理生活中各种各样的任务。

​	当今解决上述第一个问题的主流方法是用强化学习，结合IsaacGym或者Genesis进行大规模并行训练，更快地采集更多数据，训练网络解决机器人的本体控制问题。解决第二个问题的主流方法是用模仿学习，采集足够多的图像和动作数据，训练和微调网络，再部署到机器人上，VLA的思路就是如此。

​	但强化学习和模仿学习存在的问题也很明显，可解释性非常差，我们也不知道为什么神经网络能识别当前的情况、知道接下来该做什么动作，其输出不像建模时代那样可通过一系列的公式推导出。这就存在着人工智能安全问题，当然，目前也有研究人员正在探索可信和可解释人工智能，或许能解决这些问题。
​	第二个是失去了一定的自然科学性，只有工程性。比如数学和物理学等是自然科学，是在探索世界的底层真理，基于此类自然理论，发展出来的工程学，如理论力学和自动控制原理等，被用来解释工程背后的原理。目前的具身智能，更多是靠着大量的数据和堆砌的算力，研究方法距离底层理论太远了，相比之下更像劳动力密集型研究而非技术密集型。

​	我也为当今和我一样该领域的研究生感到危机，曾经强化学习很火，很多人去做，但现在我们都知道，强化学习的流程很简单了，不缺会强化学习的人，不会的人也只需要几周网课就可以上手了。现在的模型训练也必然像强化学习那样走向通俗化，变成一个基础技能。现在处于20年代初期，大模型岗位十分缺人，所以相关人才被抢夺，现在太多人一窝蜂聚集在这个赛道上，大部分做的工作就是洗数据、调模型参数，待几年后，这些技术的壁垒会越来越低，越来越多人都拥有同质的技能，将面临很严重的岗位挤兑和失业的危险。



​	联想到人类本身，我们对于脑科学的认识尚未明确。或许随着具身智能的发展，我们能逐渐揭开谜底。如果有一天现在的路子走通了，具身智能落地了，那么我们该去反思人类的智慧究竟是独一无二的，还是自然选择下的训练结果。